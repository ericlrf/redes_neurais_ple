{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Introdução ao Keras",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valmirf/redes_neurais_ple/blob/master/PyTorch/Introdu%C3%A7%C3%A3o_ao_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5focWwKA7WYc",
        "outputId": "4b4e8ccb-af5b-4ade-f5c2-faf19f4e7509",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "!git clone https://github.com/vmacf/redes_neurais.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'redes_neurais'...\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bmMqzUbgrL2"
      },
      "source": [
        "##Frameworks\n",
        "\n",
        "---\n",
        "![](https://raw.githubusercontent.com/vmacf/redes_neurais/master/KERAS/FIG/frameworks.png)\n",
        "\n",
        "\n",
        "#Empresas envolvidas\n",
        "\n",
        "![](https://raw.githubusercontent.com/vmacf/redes_neurais/master/KERAS/FIG/frameworks2.png)\n",
        "\n",
        "\n",
        "#PyTorch\n",
        "\n",
        "PyTorch é um framework de Python que funciona como uma camada em cima do Tensorflow, facilitando seu uso e facilitando procedimentos no uso de redes neurais artificiais e GPU. PyTorch tem se tornado padrão em várias empresas e institutos de pesquisa.\n",
        "\n",
        "Nesse tutorial, vamos aprender a usar o PyTorch no treinamento e utilização de uma rede neural artificial. O tutorial seguirá várias etapas, desde a leitura de uma base de dados, até o treinamento e avaliação da rede neural treinada. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtGDIv9NDnBW"
      },
      "source": [
        "#Import packages\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "from PIL import Image\n",
        "import random\n",
        "import time\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn, optim\n",
        "import time\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import matplotlib.cm as cm\n",
        "import numpy as np\n",
        "\n",
        "#Test if GPU Cuda is available\n",
        "cuda_available = torch.cuda.is_available()\n",
        "print(cuda_available)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQs7GKbgwc9w"
      },
      "source": [
        "###Nesse exercício, nós treinaremos uma rede MLP para classificar imagens da base MNIST.\n",
        "\n",
        "\n",
        "\n",
        "# 1. Carregar uma base de dados no PyTorch\n",
        "\n",
        "A biblioteca torchvision.datasets possui as principais bases de dados disponíveis para download no PyTorch (ver: https://pytorch.org/docs/stable/torchvision/datasets.html)\n",
        "\n",
        "Algumas bases de dados:\n",
        "\n",
        "*   MNIST\n",
        "*   COCO\n",
        "*   ImageNet\n",
        "*   CIFAR\n",
        "*   Flickr\n",
        "*   VOC\n",
        "*   Cityscapes\n",
        "\n",
        "\n",
        "\n",
        "Iremos usar a função DataLoader importada de TorchVision para carregar a base de dados MNIST. Usaremos um lote (batch) de tamanho 64 para treinamento e tamanho 1000 para teste neste conjunto de dados. O módulo TorchVision oferece ainda, muitas transformações úteis, como corte ou normalização. Os valores 0.1307 e 0.3081 são usados para a função Normalize(). Esses valores correspondem a média global e o desvio padrão do conjunto de dados MNIST. \n",
        "\n",
        "Usando o DataLoader, também poderíamos usar num_workers> 1, para usar subprocessos para carregar dados de forma assíncrona ou usar uma parte da memória RAM fixa (via pin_memory), para acelerar as transferências de RAM para GPU. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtuotbE9wVZ4"
      },
      "source": [
        "batch_size=64\n",
        "cuda=0\n",
        "train_size=50000\n",
        "val_size=10000\n",
        "test_size=10000\n",
        "test_batch_size=1000\n",
        "\n",
        "\n",
        "#trainset = datasets.MNIST('PATH_TO_STORE_TRAINSET', download=True, train=True, transform=transform)\n",
        "#valset = datasets.MNIST('PATH_TO_STORE_TESTSET', download=True, train=False, transform=transform)\n",
        "#trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "#valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True)\n",
        "\n",
        "#normalize with mean and standard deviation\n",
        "normalize = transforms.Normalize(mean=(0.1307,),std=(0.3081,))\n",
        "transform = transforms.Compose([transforms.ToTensor(), normalize])\n",
        "\n",
        "# define three datasets in order to have different transforms\n",
        "# on training, validation and test\n",
        "dataset_train = datasets.MNIST('/data/mnist/train', download=True, train=True, transform=transform)\n",
        "#dataset_val = datasets.MNIST('/data/mnist/val', download=True, train=True, transform=transform)\n",
        "dataset_test = datasets.MNIST('/data/mnist/test', download=True, train=False, transform=transform)\n",
        "\n",
        " \n",
        "trainloader = torch.utils.data.DataLoader(dataset_train, batch_size, shuffle=True)\n",
        "#valloader = torch.utils.data.DataLoader(dataset_val, batch_size, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(dataset_test, test_batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYpHhBH7Jq3p"
      },
      "source": [
        "Agora, vamos dar uma olhada em alguns exemplos da base de dados de teste:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foKuV0DxJ5YS"
      },
      "source": [
        "examples = enumerate(testloader)\n",
        "batch_idx, (example_data, example_targets) = next(examples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4ubYVYDJ_72"
      },
      "source": [
        "Vamos ver em que consiste um lote de dados de teste. Portanto, um lote de dados do conjunto de teste é um tensor de forma:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMLzUiuVKBPt"
      },
      "source": [
        "example_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsLIR-o5KJ8Q"
      },
      "source": [
        "Isso significa que temos 1000 exemplos de 28x28 pixels em escala de cinza (ou seja, sem canais RGB, portanto, um). Podemos plotar alguns deles usando o matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heIdoZ2iKONW"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure()\n",
        "for i in range(6):\n",
        "  plt.subplot(2,3,i+1)\n",
        "  plt.tight_layout()\n",
        "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
        "  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "fig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRlCLDdCw6jE"
      },
      "source": [
        "Ver a imagem em mais detalhes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L657_et1w1Bt"
      },
      "source": [
        "def visualize_input(img, ax): \n",
        "    #img = np.uint8(img)\n",
        "    #print('img: ', img)\n",
        "    max = img.max()\n",
        "    min = img.min()\n",
        "    data = (img-min) / (max-min) # normalize the data to 0 - 1\n",
        "    data = 255 * data # Now scale by 255\n",
        "    img = np.uint8(data)\n",
        "    #img = np.uint8(img.mul(255).numpy())\n",
        "    #print('img: ', np.uint8(img.numpy()))\n",
        "    ax.imshow(img, cmap='gray')\n",
        "    width, height = img.shape\n",
        "    thresh = img.max()/2.5\n",
        "    for x in range(width):\n",
        "        for y in range(height):\n",
        "            #ax.annotate(str(round(img[x][y],2)), xy=(y,x),\n",
        "            ax.annotate(str(img[x][y]), xy=(y,x),\n",
        "                        horizontalalignment='center',\n",
        "                        verticalalignment='center',\n",
        "                        color='white' if img[x][y]<thresh else 'black')\n",
        "\n",
        "fig = plt.figure(figsize = (12,12)) \n",
        "ax = fig.add_subplot(111)\n",
        "visualize_input(example_data[0][0], ax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OODpsCC3xWAx"
      },
      "source": [
        "Codificar os rótulos usando o One-Hot Encoding, caso precise para usar uma função como a softmax na rede. Aqui, o exemplo é ilustrativo, não a usaremos na nossa rede neural. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVADGpRBxO9Y"
      },
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "# print first ten (integer-valued) training labels\n",
        "#print('Integer-valued labels:')\n",
        "#print(example_data[0][:10])\n",
        "\n",
        "# each image in the MNIST dataset is represented as a 28x28x1\n",
        "# image, but in order to apply a standard neural network we must\n",
        "# first \"flatten\" the image to be simple list of 28x28=784 pixels\n",
        "# Flatten MNIST images into a 784 long vector\n",
        "images, labels = next(iter(trainloader))\n",
        "images2, labels2 = next(iter(testloader))\n",
        "\n",
        "print('Integer-valued labels:')\n",
        "print(labels[:10])\n",
        "\n",
        "#transform labels in one-hot condification\n",
        "lb = LabelBinarizer()\n",
        "labels_train_One_Hot = lb.fit_transform(labels)\n",
        "labels_test_One_Hot = lb.transform(labels2)\n",
        "\n",
        "# print first ten (one-hot) training labels\n",
        "print('One-hot labels:')\n",
        "print(labels_train_One_Hot[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0-sLa-0yN3p"
      },
      "source": [
        "# 2. Definir o Modelo de Arquitetura\n",
        "\n",
        "Nessa etapa, vamos definir o modelo da arquitetura da rede neural. O modelo criado terá uma camada de entrada, uma camada de saída de dez neurônios e duas camadas ocultas entre elas, uma com 128 e outra com 64 neurônios.\n",
        "\n",
        "O módulo torch.nn permite constuir a arquitetura da rede de forma bastante simples. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTqksJ8O5bT2"
      },
      "source": [
        "O módulo nn.Sequential envolve as camadas na rede. Existem três camadas lineares com a ativação da ReLU (uma função simples que permite a passagem de valores positivos, enquanto valores negativos são modificados para zero). A camada de saída é uma camada linear com a ativação da função LogSoftmax. Tecnicamente, uma função LogSoftmax é o logaritmo de uma função Softmax.\n",
        "\n",
        "Além disso, temos 784 unidades na primeira camada, porque redimensionamos cada imagem antes de enviá-la para dentro da rede neural. (28 x 28 = 784)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6G-jA1tCyM7S"
      },
      "source": [
        "input_size = 784\n",
        "hidden_sizes = [128, 64]\n",
        "output_size = 10\n",
        "\n",
        "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[1], output_size),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BhYorHa1paI"
      },
      "source": [
        "# 3. Modelo de otimização\n",
        "\n",
        "Em seguida, definimos a função de perda como a probabilidade de log negativa. Juntas, as funções LogSoftmax() e o NLLLoss(), atuam como a perda de entropia cruzada com SoftMax.\n",
        "\n",
        "\n",
        "## 3.1 Define o otimizador (SGD)\n",
        "\n",
        "[https://pytorch.org/optimizer](https://pytorch.org/cppdocs/api/classtorch_1_1optim_1_1_optimizer.html)\n",
        "\n",
        "### Tipos de otimizadores:\n",
        "*   SGD\n",
        "*   RMSprop\n",
        "*   Adagrad\n",
        "*   Adam\n",
        "\n",
        "\n",
        "## 3.2 Especifica função de perda (categorical_crossentropy)\n",
        "\n",
        "[https://pytorch.org/nn/](https://pytorch.org/docs/stable/nn.html#)\n",
        "\n",
        "### Tipos de funções de perda\n",
        "*   mean_squared_error \n",
        "*   mean_absolute_error\n",
        "*   mean_absolute_percentage_error\n",
        "*   mean_squared_logarithmic_error\n",
        "*   squared_hinge\n",
        "*   hinge\n",
        "*   categorical_hinge\n",
        "*   logcosh\n",
        "*   categorical_crossentropy\n",
        "*   sparse_categorical_crossentropy\n",
        "*   binary_crossentropy\n",
        "*   kullback_leibler_divergence\n",
        "*   poisson\n",
        "*   cosine_proximity\n",
        "\n",
        "\n",
        "## 3.3 Como escolher uma função de perda?\n",
        "\n",
        "### Funções de perda para regressão\n",
        "*   Mean Squared Error\n",
        "*   Mean Squared Logarithmic Error\n",
        "*   Mean Absolute Error\n",
        "\n",
        "### Funções de perda para classificação binária\n",
        "*   Binary Cross-Entropy\n",
        "*   Hinge\n",
        "*   Squared Hinge \n",
        "\n",
        "### Funções de perda para classificação multiclasse\n",
        "*   Multi-Class Cross-Entropy\n",
        "*   Sparse Multiclass Cross-Entropy\n",
        "*   Categorical Hinge\n",
        "*   Kullback Leibler Divergence\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8XnZ_lp1QYe"
      },
      "source": [
        "# Loss and Optimizer \n",
        "# Softmax is internally computed. \n",
        "# Set parameters to be updated. \n",
        "criterion = nn.NLLLoss()\n",
        "images, labels = next(iter(trainloader))\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "logps = model(images) #log probabilities\n",
        "loss = criterion(logps, labels) #calculate the NLL loss\n",
        "\n",
        "#optimize funcion\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUCVVZ7fzdm6"
      },
      "source": [
        "## 3.4 Atualização dos pesos\n",
        "\n",
        "Antes do passo backward, os pesos do modelo são definidos para none. Depois de chamar a função backward(), os pesos são atualizados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sidCtb2zdHb"
      },
      "source": [
        "print('Before backward pass: \\n', model[0].weight.grad)\n",
        "loss.backward()\n",
        "print('After backward pass: \\n', model[0].weight.grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFzLrHLmzqsE"
      },
      "source": [
        "# 4. Treinar o Modelo\n",
        "\n",
        "Nessa etapa, o treinamento da rede neural é realizado. Sua rede neural repete o conjunto de treinamento e atualiza os pesos. Utilizamos o módulo torch.optim, que é um módulo do PyTorch para otimizar o modelo. Nessa arquitetura, usamos a descida de gradiente e os pesos são atualizados por backpropagation. Assim, em cada época (número de vezes que repetimos o conjunto de treinamento), veremos uma diminuição gradual do valor da função de perda."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msa7ktaOzaTp"
      },
      "source": [
        "epochs = 20\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        # Flatten MNIST images into a 784 long vector\n",
        "        images = images.view(images.shape[0], -1)\n",
        "    \n",
        "        # Training pass\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(images)\n",
        "        loss = criterion(output, labels)\n",
        "        \n",
        "        #This is where the model learns by backpropagating\n",
        "        loss.backward()\n",
        "        \n",
        "        #And optimizes its weights here\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(\"Epoch {} - Training loss: {}\".format(e, running_loss/len(trainloader)))\n",
        "        #print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Aj0wRy30NFF"
      },
      "source": [
        "# 5. Avaliando o modelo no conjunto de teste\n",
        "\n",
        "Agora, o modelo treinado na etapa anterior será avaliada. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHPrlVga4R_B"
      },
      "source": [
        "images, labels = next(iter(testloader))\n",
        "\n",
        "img = images[0].view(1, 784)\n",
        "\n",
        "with torch.no_grad():\n",
        "  logps = model(img)\n",
        "\n",
        "ps = torch.exp(logps)\n",
        "probab = list(ps.numpy()[0])\n",
        "print(\"Predicted Digit =\", probab.index(max(probab)))\n",
        "print(\"Digit =\", labels.numpy()[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEwjOippACA9"
      },
      "source": [
        "Ness etapa, iteramos o conjunto de teste e calculamos o número total de previsões corretas. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01W_zbN24xqX"
      },
      "source": [
        "correct_count, all_count = 0, 0\n",
        "for images,labels in testloader:\n",
        "  for i in range(len(labels)):\n",
        "    img = images[i].view(1, 784)\n",
        "    with torch.no_grad():\n",
        "        logps = model(img)\n",
        "\n",
        "    \n",
        "    ps = torch.exp(logps)\n",
        "    probab = list(ps.numpy()[0])\n",
        "    pred_label = probab.index(max(probab))\n",
        "    true_label = labels.numpy()[i]\n",
        "    if(true_label == pred_label):\n",
        "      correct_count += 1\n",
        "    all_count += 1\n",
        "\n",
        "print(\"Number Of Images Tested =\", all_count)\n",
        "print(\"\\nModel Accuracy =\", (correct_count/all_count))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05npcHm3AV7-"
      },
      "source": [
        " ## 6. Salvando o modelo\n",
        "\n",
        "Para salvar o modelo treinado, para que não seja preciso treinar novamente quando for usar o modelo, salvamos o modelo. Quando precisarmos no futuro, podemos carregá-lo e usá-lo diretamente, sem treinamento adicional.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhRlEyBNAp38"
      },
      "source": [
        "torch.save(model, './my_mnist_model.pt') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCCDsib8YKkL"
      },
      "source": [
        "#TESTES\n",
        "1. Modifique a quantidade de camadas do modelo treinado\n",
        "2. Modifique a quantidade de neurônios na(s) camada(s) intermediárias do modelo treinado\n",
        "3. Se usar o modo de otimização com base no erro do conjunto de validação, quantas épocas você utilizaria para treinar seu modelo? Qual é o erro obtido com essa quantidade de épocas?\n",
        "4. Modifique o tipo de otimizador do seu modelo\n",
        "5. Modifique a função de perda do seu modelo\n",
        "6. Avalie combinações entre tipos de otimizador, função de perda, tipos de camadas e quantidade de épocas no treinamento. Qual foi a melhor taxa de acerto no conjunto de teste? Qual a melhor configuração de modelo que você encontrou? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qyvg8mBc46LF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}